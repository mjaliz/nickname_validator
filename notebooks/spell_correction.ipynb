{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54ab3ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import textdistance\n",
    "import re\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3fccd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('swear_words.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85a3ab95",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = df['text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c1332c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top ten words in the text are:['mound of venus', 'asslover', 's&m', 'queaf', 'whitetrash', 'meatrack', 'ra8s', 'pimp', 'urine', 'whit']\n",
      "Total Unique words are 3279.\n"
     ]
    }
   ],
   "source": [
    "V = set(words)\n",
    "print(f\"Top ten words in the text are:{words[0:10]}\")\n",
    "print(f\"Total Unique words are {len(V)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a7e26ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('کونی', 3), ('niglet', 2), ('boner', 2), ('dong', 2), ('slanteye', 2), ('muffdiving', 2), ('arsehole', 2), ('bitcher', 2), ('niggaz', 2), ('assfuck', 2)]\n"
     ]
    }
   ],
   "source": [
    "word_freq = {}  \n",
    "word_freq = Counter(words)\n",
    "print(word_freq.most_common()[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "795f7a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = {}     \n",
    "Total = sum(word_freq.values())    \n",
    "for k in word_freq.keys():\n",
    "    probs[k] = word_freq[k]/Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ad6f853",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_autocorrect(input_word):\n",
    "    input_word = input_word.lower()\n",
    "    if input_word in V:\n",
    "        return('Your word seems to be correct')\n",
    "    else:\n",
    "        sim = [1-(textdistance.Jaccard(qval=2).distance(v,input_word)) for v in word_freq.keys()]\n",
    "        df = pd.DataFrame.from_dict(probs, orient='index').reset_index()\n",
    "        df = df.rename(columns={'index':'Word', 0:'Prob'})\n",
    "        df['Similarity'] = sim\n",
    "        output = df.sort_values(['Similarity', 'Prob'], ascending=False).head()\n",
    "        return(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ecd387d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Prob</th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1719</th>\n",
       "      <td>ساک</td>\n",
       "      <td>0.000284</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1650</th>\n",
       "      <td>خایه</td>\n",
       "      <td>0.000569</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1662</th>\n",
       "      <td>جاکش</td>\n",
       "      <td>0.000284</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1720</th>\n",
       "      <td>ساکونی</td>\n",
       "      <td>0.000284</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1769</th>\n",
       "      <td>لاکونی</td>\n",
       "      <td>0.000284</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Word      Prob  Similarity\n",
       "1719     ساک  0.000284    0.333333\n",
       "1650    خایه  0.000569    0.250000\n",
       "1662    جاکش  0.000284    0.250000\n",
       "1720  ساکونی  0.000284    0.166667\n",
       "1769  لاکونی  0.000284    0.166667"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_autocorrect('خاک')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6edc5c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
